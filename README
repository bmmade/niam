
Non Intrusive Amazon Monitor (NIAM)
-----------------------------------


Most monitoring systems require a number of ports opened from source to target.

In the  (AWS) Amazon world we require a combination of Security groups, target 
ports, VPC peering connections and routes.  Generally we need to open ICMP and 
other ports from a monitoring server which is not neccessary to the good and 
safe functioning of the application. 

What would be good is a non intrusive monitoring system in which not extra ports
need be opened. Hence NIAM!

There are a few things to prepare  to get it running but this document guides you 
through it.

*******************************************************************************

We define a master AWS host which accepts messages from client AWS nodes via SQS.

SQS is cheap as follows:
	First 1 million Amazon SQS Requests per month are free
	$0.50 per 1 million Amazon SQS Requests  per month thereafter ($0.00000050 per SQS Request)


The master will also make its own checks via the aws decribe of visible instances
and perform analysis of systems which have been there and are suddenly missing.

It is in the main coded in the pure language of C.  All calls to SQS and S3 
encoded in C using low level REST API calls.

Things which have not yet been encoded or simply have to be scripts are in the scripts 
directory(see below). These may well require the use of the aws cli which must exist 
in /usr/local/bin  (or wherever you place it and modify the script).

Phase 1:

Pre-defined PINGS sent over SQS which the client sends to the master

The master will register a PING and will warn if the PING has not been seen in the last
120 seconds. If the PING has not been seen for 600 seconds then the system is purged from the 
list of systems and no further warnings will be given.


Phase 2:

Send alerts to an SNS endpoint
The SNS endpoint should already exist.

See script "Alert"


WE ARE HERE NOW!!

Phase 3:

Define other messages from client to master defined by running scripted  or otherwise checks on the client.
The client config will define the check to be made.

Phase 4:

Log historical data in a Sql database

Phase 5:

Make a web inferface


Installation
------------

Install an sql database somewhere. Of course on AWS this should be on RDS.
On ubuntu this is  done using:

Intstall he aws cli. To do this see

http://docs.aws.amazon.com/cli/latest/userguide/installing.html
(in time the need for this will be removed)

If you want to log to a sql server then install one locally or maybe use RDS.
To do this locally do:

	#sudo apt-get install mysql-server

Install hping3 with

	# apt-get install hping3

Download the niam binary and place in /usr/sbin

chmod +x /usr/sbin/niam

Create an authorization file $HOME/.awsAuth

This should contain a aws-user, aws id and secret key as follows:

aws-user:aws-id:aws-key


The defined aws-user should have certion permissions from IAM:

master		ec2 read only permissions
		S3 read permissions
		SQS permissions
		SNS permissions

client		S3 read permissions
		SQS permissions
		ec2 read only permissions

Make the permissions safe - important or niam will complain

chmod 0600 $HOME/.awsAuth


Create an s3 bucket S3 BUCKET with the subdirectories

conf
scripts

Conf directory
--------------

The conf directory should contain a file for each host that is a client or master, The 
filename should be the same as the hostname and contain the role of the system as 
either master or client

If you dont create a file equivelent to the hostname then it will look for a file called GENERIC. 
If this is basically empty then the client will only send SQS pings to the master. This is good thing!

It can contain the following statements:

(to define master or client)
ROLE=master
or
ROLE=client

(for logging to a databse)
DATABASE  database_host 3306  database user password

(for testing some endpoint)
PING $TARGET PORT $PORT
(for icmp ping then use port 0)

HTTP $TARGET PORT $PORT

Scripts directory
-----------------

The scripts directory should contain several files (for now)

The first is GetInstanceID

#cat GetInstanceID
#!/bin/bash

#You must configure your IAM user name here 
#used by both master and slave to get instance id
USER=aws-user

KEY=`grep ${USER} $HOME/.awsAuth | awk -F: '{ print $2 }'`
PASSWORD=`grep ${USER} $HOME/.awsAuth | awk -F: '{ print $3 }'`

export AWS_DEFAULT_REGION=eu-west-1
export AWS_ACCESS_KEY_ID=$KEY
export AWS_SECRET_ACCESS_KEY=$PASSWORD


if [ ! -f $HOME/.awsAuth ]
then
	echo -n "ERROR-AUTH"
fi

if [ -f /sys/hypervisor/uuid ] && [ `head -c 3 /sys/hypervisor/uuid` == ec2 ]; then

    INSTANCEID=`/usr/bin/curl -s http://169.254.169.254/latest/meta-data/instance-id | awk -F@ '{ print $1 }'`
    echo -n ${INSTANCEID}
else
    echo -n NOT-AWS 
fi


and the second is DescribeInstances

#cat DescribeInstances
#!/bin/bash


if [ ! -f $HOME/.awsAuth ]
then
	echo -n "ERROR-AUTH"
fi

USER=aws-user

KEY=`grep ${USER} $HOME/.awsAuth | awk -F: '{ print $2 }'`
PASSWORD=`grep ${USER} $HOME/.awsAuth | awk -F: '{ print $3 }'`

export AWS_DEFAULT_REGION=eu-west-1
export AWS_ACCESS_KEY_ID=$KEY
export AWS_SECRET_ACCESS_KEY=$PASSWORD

if [ -f /sys/hypervisor/uuid ] && [ `head -c 3 /sys/hypervisor/uuid` == ec2 ]; then

    /usr/local/bin/aws --output json ec2 describe-instances
else
    echo -n NOT-AWS
fi

exit 0

The third is Alert. This sends an alert if a problem is detected such as a mising ping


#!/bin/bash


if [ ! -f $HOME/.awsAuth ]
then
	echo -n "ERROR-AUTH"
fi

USER=aws-user

KEY=`grep ${USER} $HOME/.awsAuth | awk -F: '{ print $2 }'`
PASSWORD=`grep ${USER} $HOME/.awsAuth | awk -F: '{ print $3 }'`

export AWS_DEFAULT_REGION=eu-west-1
export AWS_ACCESS_KEY_ID=$KEY
export AWS_SECRET_ACCESS_KEY=$PASSWORD

SUBJECT="$1"
MESSAGE="$2"

HELPDESK="arn:aws:sns:eu-west-1:815232345528:AWSHELPDESK"

if [ -f /sys/hypervisor/uuid ] && [ `head -c 3 /sys/hypervisor/uuid` == ec2 ]; then

	/usr/local/bin/aws sns publish --topic-arn ${HELPDESK} --message "${MESSAGE}" --subject "${SUBJECT}"
else
    echo -n NOT-AWS
fi
exit 0



Running NIAM
------------

/usr/sbin/niam -s eu-west-1.queue.amazonaws.com -i aws-user  -e  s3-eu-west-1.amazonaws.com -b S3_BUCKET -q SQS_QUEUE  


-s SQS endpoint 
-i AWS user defined in $HOME/.awsAuth  
-e S3 endpoint  
-b Bucket name 
-q SQS Queue name   


The SQS Queue will be created as required by niam


Other switches are possible

-f               run in forground
-d arg           the greater the arg the more the debug output 1-10, 10-20, 20-100
-c               force to be a client  - so you can test master and client from one system
-h $hostname     fix the hostname we are supposed to be coming from




Log Files
---------

If you are running in forground then the output comes to the stdout. Otherwise log files are

logs 	/var/log/niam/niam.log		
alerts	/var/log/niam/alert.log

Scripts
-------

niam will access the S3 bucket in the scripts directory and download the two named script above into
the directory /etc/niam/scripts


Running as service
------------------

The system daemonizes upon startup unless you use the -f flag. This seem to be required when
running as a service.



#!/bin/sh

### BEGIN INIT INFO
# Provides:          service-niam 
# Required-Start:    $remote_fs $syslog
# Required-Stop:     $remote_fs $syslog
# Default-Start:     2 3 4 5
# Default-Stop:      0 1 6
# Short-Description:
# Description:       no description given
### END INIT INFO


PATH=/sbin:/usr/sbin:/bin:/usr/bin
export PATH

name=niam
program=/usr/sbin/niam

args="-f -s eu-west-1.queue.amazonaws.com -q niam_sqs -i dbo-made -e s3-eu-west-1.amazonaws.com -b bem-niam" 


pidfile="/var/run/$name.pid"

[ -r /etc/default/$name ] && . /etc/default/$name
[ -r /etc/sysconfig/$name ] && . /etc/sysconfig/$name

trace() {
  logger -t "/etc/init.d/service-niam" "$@"
}

emit() {
  trace "$@"
  echo "$@"
}

start() {

    exec $program $args >> /var/log/niam/niam.log 2>> /var/log/niam/niam.log &


    echo $! > $pidfile

    emit "$name started"

    return 0

}

stop() {
  # Try a few times to kill TERM the program
  if status ; then
    pid=$(cat "$pidfile")
    trace "Killing $name (pid $pid) with SIGTERM"
    kill -TERM $pid
    # Wait for it to exit.
    for i in 1 2 3 4 5 ; do
      trace "Waiting $name (pid $pid) to die..."
      status || break
      sleep 1
    done
    if status ; then
      emit "$name stop failed; still running."
    else
      emit "$name stopped."
    fi
  fi
}

status() {
  if [ -f "$pidfile" ] ; then
    pid=$(cat "$pidfile")
    if ps -p $pid > /dev/null 2> /dev/null ; then
      # process by this pid is running.
      # It may not be our pid, but that's what you get with just pidfiles.
      # TODO(sissel): Check if this process seems to be the same as the one we
      # expect. It'd be nice to use flock here, but flock uses fork, not exec,
      # so it makes it quite awkward to use in this case.
      return 0
    else
      return 2 # program is dead but pid file exists
    fi
  else
    return 3 # program is not running
  fi
}

force_stop() {
  if status ; then
    stop
    status && kill -KILL $(cat "$pidfile")
  fi
}


case "$1" in
  force-start|start|stop|force-stop|restart)
    trace "Attempting '$1' on service-niam"
    ;;
esac

case "$1" in
  force-start)
    PRESTART=no
    exec "$0" start
    ;;
  start)
    status
    code=$?
    if [ $code -eq 0 ]; then
      emit "$name is already running"
      exit $code
    else
      start
      exit $?
    fi
    ;;
  stop) stop ;;
  force-stop) force_stop ;;
  status) 
    status
    code=$?
    if [ $code -eq 0 ] ; then
      emit "$name is running"
    else
      emit "$name is not running"
    fi
    exit $code
    ;;
  restart) 
    
    stop && start 
    ;;
  *)
    echo "Usage: $SCRIPTNAME {start|force-start|stop|force-start|force-stop|status|restart}" >&2
    exit 3
  ;;
esac

exit $?





Messages Sent by client to master
---------------------------------

$INSTANCE,$HOSTNAME, "PING", $TIME

where

$INSTANCE   is the aws install number or NOT-AWS
$HOSTNAME   is the hostname of the Linux client
PING	    identifier of the message
$TIME	    result of time(). 
            The time as the number of seconds since the Epoch, 1970-01-01 00:00:00 +0000


$INSTANCE, $HOSTNAME, "LPING", $TARGET, $PORT,  $TIME, $STATUS

where

$INSTANCE   is the aws install number or NOT-AWS
$HOSTNAME   is the hostname of the Linux client
LPING	    identifier of the message
$TARGET	    is the host a ping was attempted on
$PORT	    the port that was pinged  (0 for ICMP)
$TIME	    result of time(). 
            The time as the number of seconds since the Epoch, 1970-01-01 00:00:00 +0000
$STATUS	    0=OK or 1=FAILED



$INSTANCE, $HOSTNAME, "HTTP", $TARGET, $PORT , $TIME, $STATUS

where

$INSTANCE   is the aws install number or NOT-AWS
$HOSTNAME   is the hostname of the Linux client
HTTP	    identifer of the message 
$PORT	    the port that was pinged  
$TARGET	    The URL 
$STATUS	    0=OK or 1=FAILED


$INSTANCE, $HOSTNAME, "SCRIPT", $SCRIPTNAME, $ARG, $TIME, $STATUS

where

$INSTANCE   is the aws install number or NOT-AWS
$HOSTNAME   is the hostname of the Linux client
SCRIPT	    identifer of the message 
$SCRIPTNAME The  path of the script 
$ARG 	    Argument to the script
$STATUS	    0=OK or 1=FAILED

